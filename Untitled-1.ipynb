{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "train_ds, test_ds = datasets.load_dataset('dbpedia_14', split=['train', 'test'])\n",
    "df_train: pd.DataFrame = train_ds.to_pandas()\n",
    "df_test: pd.DataFrame = test_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=0.25).reset_index(drop=True)\n",
    "df_test = df_test.sample(frac=0.25).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "from typing import Union, List\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class NaiveBayesModel:\n",
    "    \n",
    "    \"\"\"Multinomial NB model class template\"\"\"\n",
    "    \n",
    "    phi: np.ndarray # (N, K)\n",
    "    \n",
    "    mu: np.ndarray  # (K,)\n",
    "    \n",
    "    vocab: dict     # vocabulary map from word to row index in phi\n",
    "    \n",
    "    n_class: int    # number of classes   \n",
    "    \n",
    "    DF_Count_T: pd.core.frame.DataFrame   # word count of docs\n",
    "    \n",
    "    labels_list: List[int]\n",
    "    \n",
    "    \n",
    "    def __init__(self, vocabulary: dict, num_classes: int, DF_Count_T: pd.core.frame.DataFrame, labels_list: List[int]):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        vocabulary: {str: int} <- {word: index}\n",
    "        num_classes: Number of classes\n",
    "        \"\"\"\n",
    "        self.vocab = vocabulary\n",
    "        self.n_class = num_classes\n",
    "        self.mu = np.zeros(shape = (num_classes,))\n",
    "        N = len(vocabulary.keys())\n",
    "        self.phi = np.zeros(shape = (N, num_classes))\n",
    "        self.labels_list = labels_list\n",
    "        self.DF_Count_T = DF_Count_T\n",
    "    \n",
    "    @classmethod\n",
    "    def from_preprocessed_data(cls, docs_list: List[str], labels_list: List[int]):\n",
    "        # Extract necessary information from the training set before instantiating an object NaiveBayesModel\n",
    "        num_classes = len(set(labels_list))\n",
    "        MyVectCount = CountVectorizer(input='content', stop_words = \"english\", max_features=800)\n",
    "        DTM_Count = MyVectCount.fit_transform(docs_list)\n",
    "        ColumnNames = MyVectCount.get_feature_names()\n",
    "        DF_Count = pd.DataFrame(DTM_Count.toarray(),columns=ColumnNames)\n",
    "        DF_Count_T = DF_Count.T\n",
    "        vocab = dict()\n",
    "        for i in range(len(DF_Count_T.index)):\n",
    "            vocab[DF_Count.columns[i]] = i\n",
    "        return cls(vocab, num_classes, DF_Count_T, labels_list)\n",
    "    \n",
    "    def estimate_mu(self, alpha: float = 1.):\n",
    "        \"\"\"\n",
    "        Estimate P(Y), the prior over labels\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha: smoothing parameter\n",
    "        \"\"\"\n",
    "        for label in self.labels_list:\n",
    "            self.mu[label] += 1\n",
    "        self.mu = (self.mu + alpha) / (sum(self.mu) + self.n_class * alpha)\n",
    "        return self.mu\n",
    "    \n",
    "    def estimate_phi(self, alpha: float = 1.):\n",
    "        \"\"\"\n",
    "        Estimate phi, the N x K matrix \n",
    "        describing the probability of\n",
    "        the nth word in the kth class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha: smoothing parameter\n",
    "        \"\"\"\n",
    "        \n",
    "        class_index = [[] for i in range(self.n_class)]\n",
    "        for i in range(len(self.labels_list)):\n",
    "            class_index[self.labels_list[i]] += [i]\n",
    "            \n",
    "        for k in range(self.n_class):\n",
    "            classk = self.DF_Count_T.iloc[:,class_index[k]]\n",
    "            #the word count of all words in class k\n",
    "            classk_sum = classk.apply(lambda x: x.sum(), axis=1)\n",
    "            for word in classk_sum.index:\n",
    "                self.phi[self.vocab[word],k] = classk_sum[self.vocab[word]]\n",
    "        \n",
    "        self.phi = np.array(pd.DataFrame(self.phi).apply(lambda x: (x+alpha)/(x.sum()+len(x)*alpha), axis=0))\n",
    "        \n",
    "        return self.phi\n",
    "    \n",
    "    def predict_label(self, text: str) -> int:\n",
    "        \"\"\"\n",
    "        Compute label given some input text\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: raw input text\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        int: corresponding to the predicted label\n",
    "        \"\"\"\n",
    "        words = text.split(\" \")\n",
    "        value = list(self.mu)\n",
    "        for word in words:\n",
    "            if word in self.vocab.keys():\n",
    "                for j in range(self.n_class):\n",
    "                    value[j] = value[j] * self.phi[self.vocab[word],j]\n",
    "            else: continue\n",
    "        return value.index(max(value))\n",
    "\n",
    "model = NaiveBayesModel.from_preprocessed_data(df_train[\"content\"], df_train[\"label\"])\n",
    "x_mu = model.estimate_mu()\n",
    "x_phi = model.estimate_phi()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('TF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "263286f8e555d11a2898a0ec2a3edf48167460b52a6319f3c1490d6e47c59551"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
